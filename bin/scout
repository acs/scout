#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# This script parses IRC logs and stores the extracted data in
# a database
#
# Copyright (C) 2012-2013 Bitergia
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
#
# Authors:
#   Alvaro del Castillo San Felix <acs@bitergia.com>
#   Santiago Due√±as <sduenas@bitergia.com>
#

import json
import logging
import os
import sys

from optparse import OptionParser

from scout.database import Database
from scout.github import Github
from scout.gmane import Gmane
from scout.meetup import Meetup
from scout.reddit import Reddit
from scout.stackoverflow import Stackoverflow
from scout.utils import createJSON

def read_options():
    parser = OptionParser(usage="usage: %prog [options]",
                          version="%prog 0.1")
    parser.add_option("-b", "--backend",
                      action="store",
                      dest="backend",
                      help="Backend to use for the events " +
                            "(stackoverflow, github, ...)")
    parser.add_option("-d", "--database",
                      action="store",
                      dest="dbname",
                      help="Database where information is stored")
    parser.add_option("-u", "--db-user",
                      action="store",
                      dest="dbuser",
                      default="root",
                      help="Database user")
    parser.add_option("-p", "--db-password",
                      action="store",
                      dest="dbpassword",
                      default="",
                      help="Database password")
    parser.add_option("-g", "--debug",
                      action="store_true",
                      dest="debug",
                      default=False,
                      help="Debug mode")
    parser.add_option("-c", "--category",
                      action="store",
                      dest="category",
                      default="CentOS",
                      help="category name for the keywords")
    parser.add_option("-k", "--keywords",
                      action="store",
                      dest="keywords",
                      default="centos",
                      help="keywords to use to search events")
    parser.add_option("--key",
                      action="store",
                      dest="key",
                      help="key to be used with the API")
    parser.add_option("--events",
                      action="store_true",
                      default=False,
                      dest="events",
                      help="generate events")
    parser.add_option("--limit",
                      action="store",
                      dest="limit",
                      help="limit events number generated per backend")


    (opts, args) = parser.parse_args()

    if len(args) != 0:
        parser.error("Wrong number of arguments")

    if not (opts.dbname and opts.dbuser):
        parser.error("--database --db-user are needed")

    if opts.backend == "meetup" and not opts.key:
        parser.error("meetup backend needs --key with the API key")

    if opts.events and not opts.category:
        parser.error("keywords need the category than includes them")

    return opts


def get_datasource(backend, db, keywords, limit = None, key = None):
    ds = None

    if backend == "stackoverflow":
        ds = Stackoverflow(db, keywords, limit)
    elif backend == "github":
        ds = Github(db, keywords, limit)
    elif backend == "reddit":
        ds = Reddit(db, keywords, limit)
    elif backend == "gmane":
        ds = Gmane(db, keywords, limit)
    elif backend == "meetup":
        ds = Meetup(db, keywords, limit, key)
    else:
        logging.error(backend, " not supported")
        raise

    return ds

def add_category(category):
    # Add a category to global config file
    categories_json = "scout-categories.json"  # will include all keywords generated
    categories = []
    if os.path.isfile(categories_json):
        with open(categories_json) as f:
                categories = json.loads(f.read())
    # Search category in categories array before adding it
    found = False
    if len(categories) == 0:
        categories.append(category)
    else:
        for i in (0, len(categories)-1):
            if categories[i]['name'] == category['name']:
                categories[i] = category
                found = True
                break
        if not found:
            categories.append(category)
    with open(categories_json, 'w') as f:
        f.write(json.dumps(categories))

def create_events(backend, db, keywords, category, limit = None, key = None):
    config_json = "scout-"+",".join(keywords)+".json"
    backends = ["stackoverflow", "github", "reddit", "gmane", "meetup"]
    events = {}
    keywords_file = ",".join(keywords)

    if backend is not None:
        backends = [backend]

    if backend is not None and backend not in backends:
        logging.error(backend + " not supported")

    for backend in backends:
        events[backend] = get_datasource(backend, db, keywords, limit, key).get_events()

    res = {"events":events,
           "keywords":keywords}

    # Create JSON file with all events
    filename = keywords_file+".json"
    if limit is not None:
        filename = keywords_file+"-"+limit+".json"
    createJSON(res, filename)

    # Create a JSON file with event per data source
    for backend in events:
        res = {"events":{backend:events[backend]},
               "keywords":keywords}
        filename = keywords_file+"-"+backend+".json"
        if limit is not None:
            filename = keywords_file+"-"+backend+"-"+limit+".json"
        createJSON(res, filename)

    # Create JSON file with backends available and other config info
    config = {"backends": backends,
              "keywords": keywords,
              "limit": limit,
              "name": category}
    createJSON(config, config_json)

    add_category(config)

def download_events(backend, db, keywords, limit, key):
    create_tables(backend, db, keywords)
    ds = get_datasource(backend, db, keywords, limit, key)
    ds.download_events()


def create_tables(backend, db, keyword):
    return get_datasource(backend, db, keyword).create_tables()

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')

    opts = read_options()
    db = Database(opts.dbuser, opts.dbpassword, opts.dbname)
    db.open_database()

    keywords = opts.keywords.split(",")

    if opts.events:
        create_events(opts.backend, db, keywords, opts.category, 
                      opts.limit, opts.key)

    else:
        download_events(opts.backend, db, keywords, opts.limit, opts.key)

    db.close_database()
    sys.exit(0)
