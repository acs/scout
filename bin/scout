#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# This script parses IRC logs and stores the extracted data in
# a database
#
# Copyright (C) 2012-2013 Bitergia
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
#
# Authors:
#   Alvaro del Castillo San Felix <acs@bitergia.com>
#   Santiago Due√±as <sduenas@bitergia.com>
#

import json
import logging
import os
import sys

from optparse import OptionParser

from ConfigParser import SafeConfigParser


from scout.database import Database
from scout.github import Github
from scout.gmane import Gmane
from scout.meetup import Meetup
from scout.reddit import Reddit
from scout.stackoverflow import Stackoverflow
from scout.utils import createJSON


def read_options():
    parser = OptionParser(usage="usage: %prog [options]",
                          version="%prog 0.1")
    parser.add_option("-b", "--backend",
                      action="store",
                      dest="backend",
                      help="Backend to use for the events " +
                            "(stackoverflow, github, ...)")
    parser.add_option("-d", "--database",
                      action="store",
                      dest="dbname",
                      help="Database where information is stored")
    parser.add_option("-u", "--db-user",
                      action="store",
                      dest="dbuser",
                      default="root",
                      help="Database user")
    parser.add_option("-p", "--db-password",
                      action="store",
                      dest="dbpassword",
                      default="",
                      help="Database password")
    parser.add_option("-g", "--debug",
                      action="store_true",
                      dest="debug",
                      default=False,
                      help="Debug mode")
    parser.add_option("-c", "--category",
                      action="store",
                      dest="category",
                      default="CentOS",
                      help="category name for the keywords")
    parser.add_option("-k", "--keywords",
                      action="store",
                      dest="keywords",
                      default="centos",
                      help="keywords to use to search events")
    parser.add_option("--key",
                      action="store",
                      dest="key",
                      help="key to be used with the API")
    parser.add_option("--limit",
                      action="store",
                      dest="limit",
                      default="10",
                      help="limit events for initial quick downloading JSONs")
    parser.add_option("--conf",
                      action="store",
                      # default="scout.conf",
                      dest="config_file",
                      help="File with scout configuration")
    parser.add_option("--json-dir",
                      action="store",
                      default="html/app/data/json",
                      dest="json_dir",
                      help="Directory for storing JSON with events")

    (opts, args) = parser.parse_args()

    if len(args) != 0:
        parser.error("Wrong number of arguments")

    if not (opts.config_file):
        # All options should come from command line
        if not (opts.dbname and opts.dbuser and opts.category
                and opts.keywords):
            parser.error("--database --db-user are needed")

        if opts.backend == "meetup" and not opts.key:
            parser.error("meetup backend needs --key with the API key")

    return opts


def get_datasource(backend, db, keywords, limit=None, key=None):
    ds = None

    if backend == "stackoverflow":
        ds = Stackoverflow(db, keywords, limit)
    elif backend == "github":
        ds = Github(db, keywords, limit, key)
    elif backend == "reddit":
        ds = Reddit(db, keywords, limit)
    elif backend == "gmane":
        ds = Gmane(db, keywords, limit)
    elif backend == "meetup":
        ds = Meetup(db, keywords, limit, key)
    else:
        logging.error(backend, " not supported")
        raise

    return ds


def add_category(category, json_dir):
    # Add a category to global config file
    # It will include all keywords generated
    categories_json = "scout-categories.json"
    categories_json = os.path.join(json_dir, categories_json)

    categories = []
    if os.path.isfile(categories_json):
        with open(categories_json) as f:
                categories = json.loads(f.read())
    # Search category in categories array before adding it
    found = False
    if len(categories) == 0:
        categories.append(category)
    else:
        for i in range(0, len(categories)):
            if categories[i]['name'] == category['name']:
                for backend in category['backends']:
                    if backend not in categories[i]['backends']:
                        categories[i]['backends'].append(backend)
                    if category['limit'] is not None:
                        categories[i]['limit'] = category['limit']
                found = True
                break
        if not found:
            categories.append(category)
    with open(categories_json, 'w') as f:
        f.write(json.dumps(categories))


def create_events(backend, db, keywords, category, json_dir,
                  limit=None, key=None):
    config_json = "scout-"+",".join(keywords)+".json"
    config_json = os.path.join(json_dir, config_json)
    backends = ["stackoverflow", "github", "reddit", "gmane", "meetup"]
    events = {}
    keywords_file = ",".join(keywords)

    if backend is not None:
        backends = [backend]

    if backend is not None and backend not in backends:
        logging.error(backend + " not supported")

    for backend in backends:
        ds = get_datasource(backend, db, keywords, limit, key)
        events[backend] = ds.get_events()

    res = {"events": events,
           "keywords": keywords}

    # Create JSON file with all events. If it exists, update it
    filename = os.path.join(json_dir, keywords_file+".json")
    if limit is not None:
        filename = os.path.join(json_dir, keywords_file+"-"+limit+".json")

    if os.path.isfile(filename):
        with open(filename) as f:
            current_events = json.loads(f.read())
            for backend in events:
                current_events['events'][backend] = events[backend]
        res = current_events
    createJSON(res, filename)

    # Create a JSON file with events per data source
    for backend in events:
        res = {"events": {backend: events[backend]},
               "keywords": keywords}
        filename = os.path.join(json_dir, keywords_file+"-"+backend+".json")
        if limit is not None:
            filename = os.path.join(json_dir, keywords_file + "-" +
                                    backend + "-" + limit + ".json")
        createJSON(res, filename)

    # Create JSON file with backends available and other config info
    config = {"backends": backends,
              "keywords": keywords,
              "limit": limit,
              "name": category}
    createJSON(config, config_json)

    add_category(config, json_dir)


def download_events(backend, db, keywords, limit, key):
    create_tables(backend, db, keywords)
    ds = get_datasource(backend, db, keywords, limit, key)
    ds.download_events()


def create_tables(backend, db, keyword):
    return get_datasource(backend, db, keyword).create_tables()


def check_config_section(section, options):
    needed_options = []
    if section == "common":
        needed_options = ['db_user', 'db_password', 'db_name_prefix',
                          'backends']
    elif section == "events":
        needed_options = []
    elif "category_" in section:
        needed_options = ['keywords']

    for option in needed_options:
        if option not in options:
            raise Exception(section + " config section needs " + option)
            sys.exit(1)


def config_scout(opts, categories):
    logging.info("Using " + opts.config_file + " for configuring scout")

    parser = SafeConfigParser()
    conf_file = opts.config_file
    with open(conf_file, 'r') as fd:
        parser.readfp(fd)

    sections = parser.sections()

    # Sections are: global, one section per category and events
    needed_sections = ['common', 'events']
    for section in needed_sections:
        if section not in sections:
            raise(Exception("Bad config file. Needed section not found " +
                            section))

    for section in sections:
        options = parser.options(section)
        check_config_section(section, options)
        if section == "common":
            opts.dbname = parser.get(section, 'db_name_prefix')
            opts.dbuser = parser.get(section, 'db_user')
            opts.dbpassword = parser.get(section, 'db_password')
            opts.backends = parser.get(section, 'backends').split(",")
            if 'meetup_key' in options:
                opts.meetup_key = parser.get(section, 'meetup_key')
            if 'bigquery_credentials' in options:
                opts.bigquery_credentials = \
                    parser.get(section, 'bigquery_credentials')
        elif section.find("category_") == 0:
            category = section.replace("category_", "")
            categories[category] = parser.get(section, 'keywords').split(",")
        elif section == "events":
            if 'limit' in options:
                opts.limit = parser.get(section, 'limit')
        else:
            logging.warning("Unknown section " + section)


def get_backend_key(backend):
    """ Get the API key for a backend """

    key = opts.key  # Use the key provided in command line by default
    if backend == "meetup":
        try:
            if opts.meetup_key is not None:
                # config file includes the key
                key = opts.meetup_key
        except:  # meetup_key not defined
            pass
    elif backend == "github":
        try:
            if opts.bigquery_credentials is not None:
                # config file includes the key
                key = opts.bigquery_credentials
        except:  # meetup_key not defined
            pass

    return key

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')

    categories = {}  # dict with category and its keywords

    opts = read_options()  # opts used in all places as config object

    # We can receive config from command line or from config file
    if opts.config_file:
        if not os.path.isfile(opts.config_file):
            raise(Exception("Can not find config file " + opts.config_file))
        else:
            # Fill opts with config info from the file
            config_scout(opts, categories)
    else:
        categories[opts.category] = opts.keywords.split(",")
        opts.backends = [opts.backend]

    for category in categories:
        keywords = categories[category]

        # One database for category
        db = Database(opts.dbuser, opts.dbpassword, opts.dbname+"_"+category)
        cleandb = True  # Until we have incremental mode, recreate dbs
        db.open_database(cleandb)

        for backend in opts.backends:

            logging.info("Generating " + category + " in " + backend)

            limit = None  # not used in data gathering

            download_events(backend, db, keywords,
                            limit, get_backend_key(backend))

            # Generate all events
            create_events(backend, db, keywords, category, opts.json_dir,
                          limit, get_backend_key(backend))

            if opts.limit:
                # Generate a limited list of events for initial downloading
                create_events(backend, db, keywords, category, opts.json_dir,
                              opts.limit, get_backend_key(backend))

        db.close_database()

    sys.exit(0)
